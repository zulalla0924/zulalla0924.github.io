{"content":"{\"__ud_title\":\"Nvidia Api LLM model id\",\"__ud_tags\":[\"ai\",\"vibecoding\"],\"__ud_update_time\":1770599867265,\"__ud_create_time\":1770548240812,\"__ud_draft\":false,\"type\":\"doc\",\"content\":[{\"type\":\"heading\",\"attrs\":{\"level\":1,\"id\":null},\"content\":[{\"type\":\"text\",\"text\":\"Nvidia Api LLM model id\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"NVIDIA build models , here are the model IDs organized by category: Large Language Models (LLMs)\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":null},\"content\":[{\"type\":\"text\",\"text\":\"nvidia/nemotron-3-nano-30b-a3b - Open, efficient MoE model with 1M context\\ndeepseek-ai/deepseek-v3.2 - 685B reasoning LLM with sparse attention\\ndeepseek-ai/deepseek-v3.1 - Hybrid AI model with fast reasoning\\nminimaxai/minimax-m2 - 230B MoE model (10B active)\\nqwen/qwen3-235b-a22b - Advanced reasoning MoE model\\nqwen/qwq-32b - Powerful reasoning model\\nmistralai/mistral-nemotron - Built for agentic workflows\\nigenius/colosseum_355b_instruct_16k - Multilingual LLM for regulated industries\\ntiiuae/falcon3-7b-instruct - Instruction tuned LLM\\nigenius/italia_10b_instruct_16k - European languages focused LLM\\nmeta/llama-3.1-405b-instruct - Advanced LLM for synthetic data generation\\nmeta/llama-3.1-8b-instruct - State-of-the-art model\\nmeta/llama3-70b-instruct - Complex conversations model\\nmeta/llama3-8b-instruct - Advanced LLM\\nmeta/llama-3.2-3b-instruct - Small language model\\nmeta/llama-3.2-1b-instruct - Small language model\\nqwen/qwen2-7b-instruct - Chinese and English LLM\\nthudm/chatglm3-6b - Chinese and English chatbot\\ngoogle/gemma-2-27b-it - Text generation model\\ngoogle/gemma-2-9b-it - Text generation model\\ngoogle/gemma-7b - Text generation model\\nrakuten/rakutenai-7b-chat - Advanced LLM\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Vision-Language Models\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":null},\"content\":[{\"type\":\"text\",\"text\":\"nvidia/nemotron-parse - Vision-language model for text/metadata extraction\\nnvidia/nemotron-nano-12b-v2-vl - Multi-image and video understanding\\nnvidia/cosmos-reason2-8b - Physical world understanding\\ngoogle/gemma-3n-e4b-it - Edge computing AI with multimodal input\\ngoogle/gemma-3n-e2b-it - Edge computing AI with multimodal input\\ngoogle/gemma-3-27b-it - Multimodal model for image reasoning\\ngoogle/paligemma - Vision language model\\nnvidia/nv-clip - Multimodal embeddings model\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Scientific/Bio Models\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":null},\"content\":[{\"type\":\"text\",\"text\":\"openfold/openfold3 - Biomolecular foundation model\\nopenfold/openfold2 - Protein 3D structure prediction\\nmit/boltz-2 - Complex structure prediction\\narc/evo2-40b - Biological foundation model\\nmeta/esm2-650m - Protein embeddings\\nmeta/esmfold - Protein 3D structure prediction\\nipd/proteinmpnn - Amino acid sequence prediction\\nipd/rfdiffusion - Protein backbone generation\\nmit/diffdock - Molecule-protein interaction prediction\\nnvidia/maisi - 3D CT Latent Diffusion model\\nnvidia/genmol - Molecular generation\\nnvidia/molmim-generate - Controlled molecular generation\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Autonomous Driving\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":null},\"content\":[{\"type\":\"text\",\"text\":\"nvidia/streampetr - 3D object detection\\nnvidia/sparsedrive - End-to-end autonomous driving stack\\nnvidia/bevformer - Bird's-eye-view 3D perception\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"3D/Computer Vision\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":null},\"content\":[{\"type\":\"text\",\"text\":\"microsoft/trellis - 3D asset generation\\nnvidia/cosmos-transfer1-7b - Physics-aware video generation\\nnvidia/cosmos-predict1-5b - Future frame prediction\\nnvidia/nv-dinov2 - Visual foundation model\\nnvidia/visual-changenet - Change detection between images\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Specialized Models\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":null},\"content\":[{\"type\":\"text\",\"text\":\"nvidia/nemoretriever-ocr - OCR for text extraction\\nnvidia/nv-embedcode-7b-v1 - Code retrieval embeddings\\nnvidia/llama-3.2-nv-embedqa-1b-v2 - Question-answering retrieval\\nnvidia/usdcode - OpenUSD code generation\\nnvidia/usdsearch - OpenUSD asset search\\nnvidia/usdvalidate - OpenUSD asset validation\\nnvidia/audio2face-3d - Audio to facial blendshapes\\nnvidia/eyecontact - Gaze angle estimation\\nnvidia/studiovoice - Speech enhancement\\nnvidia/vista-3d - 3D medical imaging segmentation\\nnvidia/ocdrnet - Optical character detection/recognition\\nnvidia/corrdiff - Weather field generation\\nnvidia/fourcastnet - Atmospheric dynamics prediction\\nnvidia/cuopt - Route optimization\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Other Models\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":null},\"content\":[{\"type\":\"text\",\"text\":\"baidu/paddleocr - Table extraction and OCR\\nbaai/bge-m3 - Text retrieval embeddings\\nnvidia/rerank-qa-mistral-4b - Question-answering reranking\\ncolabfold/msa-search - Protein sequence alignment\\nuniversity-at-buffalo/cached - Chart element detection\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"These models are available through NVIDIA's NIM (NVIDIA Inference Microservices) APIs for deployment and inference.\"}]},{\"type\":\"paragraph\",\"content\":[{\"type\":\"text\",\"text\":\"Full list: \"},{\"type\":\"text\",\"marks\":[{\"type\":\"link\",\"attrs\":{\"href\":\"https://build.nvidia.com/models\",\"target\":\"_blank\",\"rel\":\"nofollow\",\"class\":null}}],\"text\":\"build.nvidia.com/models\"}]},{\"type\":\"codeBlock\",\"attrs\":{\"language\":null},\"content\":[{\"type\":\"text\",\"text\":\"Model \\tDescription\\nminimaxai/minimax-m2.1 \\tMinimax latest, strong Chinese capability\\nz-ai/glm4.7 \\tZhipu GLM4, fast response\\nmeta/llama-3.3-70b-instruct \\tMeta Llama 3.3 70B\\nmeta/llama-3.1-405b-instruct \\tMeta Llama 3.1 405B\\ndeepseek-ai/deepseek-r1 \\tDeepSeek R1 reasoning model\\nqwen/qwen2.5-72b-instruct \\tAlibaba Qwen 2.5\\n\"}]}]}","title":"Nvidia Api LLM model id","tags":["ai","vibecoding"],"updateTime":1770599867265,"createTime":1770548240812,"draft":false,"intro":"NVIDIA build models , here are the model IDs organized by category: Large Language Models (LLMs)","html":"<h1 level=\"1\" id=\"Nvidia-Api-LLM-model-id\">Nvidia Api LLM model id</h1><p>NVIDIA build models , here are the model IDs organized by category: Large Language Models (LLMs)</p><div class=\"llt-code readonly\"><div class=\"language\">bash</div><div class=\"wrapper\"><pre><code>nvidia/nemotron-3-nano-30b-a3b - Open, efficient MoE model with 1M context\ndeepseek-ai/deepseek-v3.2 - 685B reasoning LLM with sparse attention\ndeepseek-ai/deepseek-v3.1 - Hybrid AI model with fast reasoning\nminimaxai/minimax-m2 - 230B MoE model (10B active)\nqwen/qwen3-235b-a22b - Advanced reasoning MoE model\nqwen/qwq-32b - Powerful reasoning model\nmistralai/mistral-nemotron - Built <span class=\"hljs-keyword\" class=\"hljs-keyword\">for</span> agentic workflows\nigenius/colosseum_355b_instruct_16k - Multilingual LLM <span class=\"hljs-keyword\" class=\"hljs-keyword\">for</span> regulated industries\ntiiuae/falcon3-7b-instruct - Instruction tuned LLM\nigenius/italia_10b_instruct_16k - European languages focused LLM\nmeta/llama-3.1-405b-instruct - Advanced LLM <span class=\"hljs-keyword\" class=\"hljs-keyword\">for</span> synthetic data generation\nmeta/llama-3.1-8b-instruct - State-of-the-art model\nmeta/llama3-70b-instruct - Complex conversations model\nmeta/llama3-8b-instruct - Advanced LLM\nmeta/llama-3.2-3b-instruct - Small language model\nmeta/llama-3.2-1b-instruct - Small language model\nqwen/qwen2-7b-instruct - Chinese and English LLM\nthudm/chatglm3-6b - Chinese and English chatbot\ngoogle/gemma-2-27b-it - Text generation model\ngoogle/gemma-2-9b-it - Text generation model\ngoogle/gemma-7b - Text generation model\nrakuten/rakutenai-7b-chat - Advanced LLM</code></pre></div></div><p>Vision-Language Models</p><div class=\"llt-code readonly\"><div class=\"language\">bash</div><div class=\"wrapper\"><pre><code>nvidia/nemotron-parse - Vision-language model <span class=\"hljs-keyword\" class=\"hljs-keyword\">for</span> text/metadata extraction\nnvidia/nemotron-nano-12b-v2-vl - Multi-image and video understanding\nnvidia/cosmos-reason2-8b - Physical world understanding\ngoogle/gemma-3n-e4b-it - Edge computing AI with multimodal input\ngoogle/gemma-3n-e2b-it - Edge computing AI with multimodal input\ngoogle/gemma-3-27b-it - Multimodal model <span class=\"hljs-keyword\" class=\"hljs-keyword\">for</span> image reasoning\ngoogle/paligemma - Vision language model\nnvidia/nv-clip - Multimodal embeddings model</code></pre></div></div><p>Scientific/Bio Models</p><div class=\"llt-code readonly\"><div class=\"language\">bash</div><div class=\"wrapper\"><pre><code>openfold/openfold3 - Biomolecular foundation model\nopenfold/openfold2 - Protein 3D structure prediction\nmit/boltz-2 - Complex structure prediction\narc/evo2-40b - Biological foundation model\nmeta/esm2-650m - Protein embeddings\nmeta/esmfold - Protein 3D structure prediction\nipd/proteinmpnn - Amino acid sequence prediction\nipd/rfdiffusion - Protein backbone generation\nmit/diffdock - Molecule-protein interaction prediction\nnvidia/maisi - 3D CT Latent Diffusion model\nnvidia/genmol - Molecular generation\nnvidia/molmim-generate - Controlled molecular generation</code></pre></div></div><p>Autonomous Driving</p><div class=\"llt-code readonly\"><div class=\"language\">vbnet</div><div class=\"wrapper\"><pre><code>nvidia/streampetr - <span class=\"hljs-number\" class=\"hljs-number\">3</span>D <span class=\"hljs-type\" class=\"hljs-type\">object</span> detection\nnvidia/sparsedrive - <span class=\"hljs-keyword\" class=\"hljs-keyword\">End</span>-<span class=\"hljs-keyword\" class=\"hljs-keyword\">to</span>-<span class=\"hljs-keyword\" class=\"hljs-keyword\">end</span> autonomous driving stack\nnvidia/bevformer - Bird<span class=\"hljs-comment\" class=\"hljs-comment\">&apos;s-eye-view 3D perception</span></code></pre></div></div><p>3D/Computer Vision</p><div class=\"llt-code readonly\"><div class=\"language\">bash</div><div class=\"wrapper\"><pre><code>microsoft/trellis - 3D asset generation\nnvidia/cosmos-transfer1-7b - Physics-aware video generation\nnvidia/cosmos-predict1-5b - Future frame prediction\nnvidia/nv-dinov2 - Visual foundation model\nnvidia/visual-changenet - Change detection between images</code></pre></div></div><p>Specialized Models</p><div class=\"llt-code readonly\"><div class=\"language\">bash</div><div class=\"wrapper\"><pre><code>nvidia/nemoretriever-ocr - OCR <span class=\"hljs-keyword\" class=\"hljs-keyword\">for</span> text extraction\nnvidia/nv-embedcode-7b-v1 - Code retrieval embeddings\nnvidia/llama-3.2-nv-embedqa-1b-v2 - Question-answering retrieval\nnvidia/usdcode - OpenUSD code generation\nnvidia/usdsearch - OpenUSD asset search\nnvidia/usdvalidate - OpenUSD asset validation\nnvidia/audio2face-3d - Audio to facial blendshapes\nnvidia/eyecontact - Gaze angle estimation\nnvidia/studiovoice - Speech enhancement\nnvidia/vista-3d - 3D medical imaging segmentation\nnvidia/ocdrnet - Optical character detection/recognition\nnvidia/corrdiff - Weather field generation\nnvidia/fourcastnet - Atmospheric dynamics prediction\nnvidia/cuopt - Route optimization</code></pre></div></div><p>Other Models</p><div class=\"llt-code readonly\"><div class=\"language\">bash</div><div class=\"wrapper\"><pre><code>baidu/paddleocr - Table extraction and OCR\nbaai/bge-m3 - Text retrieval embeddings\nnvidia/rerank-qa-mistral-4b - Question-answering reranking\ncolabfold/msa-search - Protein sequence alignment\nuniversity-at-buffalo/cached - Chart element detection</code></pre></div></div><p>These models are available through NVIDIA&apos;s NIM (NVIDIA Inference Microservices) APIs for deployment and inference.</p><p>Full list: <a target=\"_blank\" rel=\"nofollow\" href=\"https://build.nvidia.com/models\">build.nvidia.com/models</a></p><div class=\"llt-code readonly\"><div class=\"language\">bash</div><div class=\"wrapper\"><pre><code>Model \tDescription\nminimaxai/minimax-m2.1 \tMinimax latest, strong Chinese capability\nz-ai/glm4.7 \tZhipu GLM4, fast response\nmeta/llama-3.3-70b-instruct \tMeta Llama 3.3 70B\nmeta/llama-3.1-405b-instruct \tMeta Llama 3.1 405B\ndeepseek-ai/deepseek-r1 \tDeepSeek R1 reasoning model\nqwen/qwen2.5-72b-instruct \tAlibaba Qwen 2.5\n</code></pre></div></div><script type=\"module\">const injectHtml = (root, html) => {\n  const iframe = document.createElement(\"iframe\");\n  const htmlContent = `<html><head></head><body>${html}</body></html>`;\n  iframe.style.width = \"100%\";\n  iframe.style.height = \"100%\";\n  iframe.onload = () => {\n    const doc = iframe.contentDocument || iframe.contentWindow?.document;\n    if (!doc) {\n      return;\n    }\n    doc.open();\n    doc.write(htmlContent);\n    doc.close();\n  };\n  root.replaceChildren(iframe);\n}\n  document.querySelectorAll('.playground')?.forEach(el=>{\n    const html = el.getAttribute('data-html');\n    if (html) {\n      injectHtml(el,html);\n    }\n    const indicator = document.createElement(\"div\");\n    indicator.className = \"indicator\";\n    const showCode = document.createElement(\"div\");\n    showCode.className = \"show-code\";\n    showCode.innerText = \"code\";\n    showCode.onclick = () => {\n      el.parentElement.classList.remove(\"preview-only\");\n    };\n    const showPreview = document.createElement(\"div\");\n    showPreview.className = \"show-preview\";\n    showPreview.innerText = \"preview\";\n    showPreview.onclick = () => {\n      el.parentElement.classList.add(\"preview-only\");\n    };\n    indicator.appendChild(showCode);\n    indicator.appendChild(showPreview);\n    el.parentElement.appendChild(indicator);\n    if (window.screen.width < 768) {\n      showPreview.click();\n    }\n  });</script>","id":"Nvidia-Api-LLM-model-id","path":"/posts/Nvidia-Api-LLM-model-id.json"}